{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-15T04:36:43.921238Z","iopub.execute_input":"2024-08-15T04:36:43.922046Z","iopub.status.idle":"2024-08-15T04:36:44.982790Z","shell.execute_reply.started":"2024-08-15T04:36:43.922014Z","shell.execute_reply":"2024-08-15T04:36:44.981660Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Thu Aug 15 04:36:44 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"å¤§å‹è¯­è¨€æ¨¡å‹ä»¥å…¶æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›è€Œé—»åã€‚åœ¨é¢„è®­ç»ƒæœŸé—´ï¼Œå®ƒä»¬æ¥å—äº†æ•°ç™¾ä¸‡ä¸ªtokensçš„è®­ç»ƒã€‚è¿™å°†æœ‰åŠ©äºå¤§å‹è¯­è¨€æ¨¡å‹ç†è§£è‹±æ–‡æ–‡æœ¬å¹¶åœ¨ç”ŸæˆæœŸé—´ç”Ÿæˆæœ‰æ„ä¹‰çš„å®Œæ•´æ ‡è®°ã€‚è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å¦ä¸€ä¸ªå¸¸è§ä»»åŠ¡æ˜¯åºåˆ—åˆ†ç±»ä»»åŠ¡ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬å°†ç»™å®šçš„åºåˆ—åˆ†ç±»ä¸ºä¸åŒçš„ç±»åˆ«ã€‚è¿™å¯ä»¥é€šè¿‡ prompt ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç®€å•åœ°å®Œæˆï¼Œä½†è¿™å¯èƒ½åªæ˜¯æœ‰æ—¶æœ‰æ•ˆã€‚æˆ‘ä»¬å¯ä»¥è°ƒæ•´å¤§å‹è¯­è¨€æ¨¡å‹ä»¥é’ˆå¯¹ç»™å®šçš„è¾“å…¥ä¸ºæ¯ä¸ªç±»åˆ«è¾“å‡ºä¸€ç»„æ¦‚ç‡ã€‚æœ¬æŒ‡å—å°†å±•ç¤ºå¦‚ä½•è®­ç»ƒæ­¤ç±» LLM å¹¶ä½¿ç”¨å¾®è°ƒçš„ Llama 3 æ¨¡å‹ã€‚","metadata":{}},{"cell_type":"markdown","source":"ä¸‹è½½å¿…è¦çš„åº“ï¼Œæˆ‘ä»¬éœ€è¦è¿™äº›åº“æ¥å¾®è°ƒLlama 3è¿›è¡Œåºåˆ—åˆ†ç±»ã€‚è®©æˆ‘ä»¬è¿è¡Œä»¥ä¸‹ä»£ç ï¼š","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers accelerate trl bitsandbytes datasets evaluate\n!pip install -q peft scikit-learn","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:37:08.427169Z","iopub.execute_input":"2024-08-15T04:37:08.427603Z","iopub.status.idle":"2024-08-15T04:37:39.610478Z","shell.execute_reply.started":"2024-08-15T04:37:08.427575Z","shell.execute_reply":"2024-08-15T04:37:39.609263Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!huggingface-cli login --token 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","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:37:43.794918Z","iopub.execute_input":"2024-08-15T04:37:43.795677Z","iopub.status.idle":"2024-08-15T04:37:45.483510Z","shell.execute_reply.started":"2024-08-15T04:37:43.795642Z","shell.execute_reply":"2024-08-15T04:37:45.482581Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åŠ è½½æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\n# ä¸‹è½½æ•°æ®ï¼šhttps://huggingface.co/datasets/fancyzhx/ag_news\ndataset = load_dataset(\"ag_news\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:37:56.422970Z","iopub.execute_input":"2024-08-15T04:37:56.423460Z","iopub.status.idle":"2024-08-15T04:38:05.744122Z","shell.execute_reply.started":"2024-08-15T04:37:56.423421Z","shell.execute_reply":"2024-08-15T04:38:05.743302Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/8.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7d35cd102014a4f9f1027c270b51afe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/18.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b96bdaa437ad442eac9c061074127114"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"851a018aaf61490ebfc9f1bff859a408"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"733dc81d353a476691e1c7be78e72935"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bf7811e2f574b2f9503b1dc0ceefd59"}},"metadata":{}}]},{"cell_type":"markdown","source":"è¿™æ˜¯ä¸€ä¸ªæ–°é—»åˆ†ç±»æ•°æ®é›†ã€‚æ–°é—»åˆ†ä¸ºä¸åŒçš„ç±»åˆ«ï¼Œä¾‹å¦‚ä¸–ç•Œã€ä½“è‚²ã€å•†ä¸šå’Œç§‘å­¦/æŠ€æœ¯ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹æ¯ä¸ªç±»åˆ«çš„ç¤ºä¾‹æ•°é‡æ˜¯å¦ç›¸ç­‰ï¼Œæˆ–è€…æ˜¯å¦å­˜åœ¨ç±»åˆ«ä¸å¹³è¡¡ã€‚","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(dataset['train'])\n\ndf.label.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:38:17.014621Z","iopub.execute_input":"2024-08-15T04:38:17.015185Z","iopub.status.idle":"2024-08-15T04:38:21.392143Z","shell.execute_reply.started":"2024-08-15T04:38:17.015154Z","shell.execute_reply":"2024-08-15T04:38:21.391093Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"label\n2    0.25\n3    0.25\n1    0.25\n0    0.25\nName: proportion, dtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"è¿è¡Œæ­¤ä»£ç ä¼šäº§ç”Ÿä»¥ä¸‹è¾“å‡ºã€‚æˆ‘ä»¬å¯ä»¥æ£€æŸ¥æ‰€æœ‰ 4 ä¸ªæ ‡ç­¾æ˜¯å¦å…·æœ‰ç›¸åŒçš„æ¯”ä¾‹ï¼Œè¿™æ„å‘³ç€æ¯ä¸ªç±»åˆ«åœ¨æ•°æ®é›†ä¸­éƒ½æœ‰ç›¸åŒæ•°é‡çš„ç¤ºä¾‹ã€‚æ•°æ®é›†å¾ˆå¤§ï¼Œæ‰€ä»¥æˆ‘ä»¬åªéœ€è¦å…¶ä¸­çš„ä¸€éƒ¨åˆ†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç ä»æ­¤æ•°æ®æ¡†ä¸­æŠ½å–ä¸€äº›æ•°æ®ï¼š","metadata":{}},{"cell_type":"code","source":"# Splitting the dataframe into 4 separate dataframes based on the labels\nlabel_1_df = df[df['label'] == 0]\nlabel_2_df = df[df['label'] == 1]\nlabel_3_df = df[df['label'] == 2]\nlabel_4_df = df[df['label'] == 3]\n\n# Shuffle each label dataframe\nlabel_1_df = label_1_df.sample(frac=1).reset_index(drop=True)\nlabel_2_df = label_2_df.sample(frac=1).reset_index(drop=True)\nlabel_3_df = label_3_df.sample(frac=1).reset_index(drop=True)\nlabel_4_df = label_4_df.sample(frac=1).reset_index(drop=True)\n\n# Splitting each label dataframe into train, test, and validation sets\nlabel_1_train = label_1_df.iloc[:2000]\nlabel_1_test = label_1_df.iloc[2000:2500]\nlabel_1_val = label_1_df.iloc[2500:3000]\n\nlabel_2_train = label_2_df.iloc[:2000]\nlabel_2_test = label_2_df.iloc[2000:2500]\nlabel_2_val = label_2_df.iloc[2500:3000]\n\nlabel_3_train = label_3_df.iloc[:2000]\nlabel_3_test = label_3_df.iloc[2000:2500]\nlabel_3_val = label_3_df.iloc[2500:3000]\n\nlabel_4_train = label_4_df.iloc[:2000]\nlabel_4_test = label_4_df.iloc[2000:2500]\nlabel_4_val = label_4_df.iloc[2500:3000]\n\n# Concatenating the splits back together\ntrain_df = pd.concat([label_1_train, label_2_train, label_3_train, label_4_train])\ntest_df = pd.concat([label_1_test, label_2_test, label_3_test, label_4_test])\nval_df = pd.concat([label_1_val, label_2_val, label_3_val, label_4_val])\n\n# Shuffle the dataframes to ensure randomness\ntrain_df = train_df.sample(frac=1).reset_index(drop=True)\ntest_df = test_df.sample(frac=1).reset_index(drop=True)\nval_df = val_df.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:38:36.746366Z","iopub.execute_input":"2024-08-15T04:38:36.746751Z","iopub.status.idle":"2024-08-15T04:38:36.793756Z","shell.execute_reply.started":"2024-08-15T04:38:36.746724Z","shell.execute_reply":"2024-08-15T04:38:36.792650Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"æˆ‘ä»¬çš„æ•°æ®åŒ…å« 4 ä¸ªæ ‡ç­¾ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åˆ›å»º 4 ä¸ªæ•°æ®æ¡†ï¼Œæ¯ä¸ªæ•°æ®æ¡†ç”±ä¸€ä¸ªæ ‡ç­¾ç»„æˆã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡è°ƒç”¨ sample å‡½æ•°æ¥æ‰“ä¹±æ¯ä¸ªæ ‡ç­¾ï¼Œç„¶åï¼Œæˆ‘ä»¬å°†æ¯ä¸ªæ ‡ç­¾æ•°æ®æ¡†åˆ†æˆ 3 ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«ç§°ä¸ºè®­ç»ƒã€æµ‹è¯•å’Œæœ‰æ•ˆæ•°æ®æ¡†ã€‚å¯¹äºè®­ç»ƒï¼Œæˆ‘ä»¬æä¾› 2000 ä¸ªæ ‡ç­¾ï¼Œå¯¹äºæµ‹è¯•å’ŒéªŒè¯ï¼Œæˆ‘ä»¬å„æä¾› 500 ä¸ªæ ‡ç­¾ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬é€šè¿‡pd.concat() å‡½æ•°å°†æ‰€æœ‰æ ‡ç­¾çš„è®­ç»ƒæ•°æ®æ¡†åˆå¹¶ä¸ºä¸€ä¸ªè®­ç»ƒæ•°æ®æ¡†ï¼Œæˆ‘ä»¬å¯¹æµ‹è¯•å’ŒéªŒè¯æ•°æ®æ¡†ä¹Ÿåšäº†åŒæ ·çš„äº‹æƒ…ã€‚æœ€åï¼Œæˆ‘ä»¬å†æ¬¡å¯¹ train_dfã€test_df å’Œ valid_df è¿›è¡Œæ··æ´—ï¼Œä»¥ç¡®ä¿å®ƒä»¬çš„éšæœºæ€§ã€‚","metadata":{}},{"cell_type":"markdown","source":"ä¸ºäº†ç¡®è®¤ï¼Œè®©æˆ‘ä»¬æ£€æŸ¥è®­ç»ƒæ•°æ®æ¡†ä¸­æ¯ä¸ªæ ‡ç­¾çš„å€¼è®¡æ•°ã€‚ä»£ç å¦‚ä¸‹ï¼š","metadata":{}},{"cell_type":"code","source":"train_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:38:48.673728Z","iopub.execute_input":"2024-08-15T04:38:48.674742Z","iopub.status.idle":"2024-08-15T04:38:48.682123Z","shell.execute_reply.started":"2024-08-15T04:38:48.674705Z","shell.execute_reply":"2024-08-15T04:38:48.681115Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"label\n2    2000\n0    2000\n3    2000\n1    2000\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"æˆ‘ä»¬å¯ä»¥æ£€æŸ¥è®­ç»ƒæ•°æ®æ¡†æ˜¯å¦å¯¹å››ä¸ªæ ‡ç­¾éƒ½å…·æœ‰ç›¸åŒçš„ç¤ºä¾‹ã€‚åœ¨å°†å®ƒä»¬å‘é€åˆ°è®­ç»ƒä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å°†è¿™äº› Pandas DataFrames è½¬æ¢ä¸º HuggingFace è®­ç»ƒåº“æ¥å—çš„ DatasetDictã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š","metadata":{}},{"cell_type":"code","source":"from datasets import DatasetDict, Dataset\n\n# Converting pandas DataFrames into Hugging Face Dataset objects:\ndataset_train = Dataset.from_pandas(train_df)\ndataset_val = Dataset.from_pandas(val_df)\ndataset_test = Dataset.from_pandas(test_df)\n\n# Combine them into a single DatasetDict\ndataset = DatasetDict({\n    'train': dataset_train,\n    'val': dataset_val,\n    'test': dataset_test\n})\n\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:39:03.523602Z","iopub.execute_input":"2024-08-15T04:39:03.523997Z","iopub.status.idle":"2024-08-15T04:39:03.567833Z","shell.execute_reply.started":"2024-08-15T04:39:03.523967Z","shell.execute_reply":"2024-08-15T04:39:03.566881Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 8000\n    })\n    val: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:55:40.897914Z","iopub.execute_input":"2024-08-15T06:55:40.898734Z","iopub.status.idle":"2024-08-15T06:55:40.905257Z","shell.execute_reply.started":"2024-08-15T06:55:40.898702Z","shell.execute_reply":"2024-08-15T06:55:40.904376Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"{'text': 'A Windfall for a Student Loan Program The student loan industry is collecting a record amount of the old subsidies Congress thought it had retired.',\n 'label': 2}"},"metadata":{}}]},{"cell_type":"markdown","source":"ä»è¾“å‡ºä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒDatasetDict åŒ…å« 3 ä¸ªæ•°æ®é›†ï¼Œåˆ†åˆ«æ˜¯è®­ç»ƒã€æµ‹è¯•å’ŒéªŒè¯æ•°æ®é›†ã€‚å…¶ä¸­æ¯ä¸ªæ•°æ®é›†ä»…åŒ…å« 2 åˆ—ï¼šä¸€åˆ—æ˜¯æ–‡æœ¬ï¼Œå¦ä¸€åˆ—æ˜¯æ ‡ç­¾ã€‚\n\nåœ¨è¿™é‡Œï¼Œåœ¨æˆ‘ä»¬çš„æ•°æ®é›†ä¸­ï¼Œæ¯ä¸ªç±»åˆ«çš„æ¯”ä¾‹æ˜¯ç›¸åŒçš„ã€‚åœ¨å®é™…æƒ…å†µä¸­ï¼Œè¿™å¯èƒ½åªæ˜¯æœ‰æ—¶æ˜¯æ­£ç¡®çš„ã€‚å› æ­¤ï¼Œå½“ç±»åˆ«ä¸å¹³è¡¡æ—¶ï¼Œæˆ‘ä»¬éœ€è¦é‡‡å–é€‚å½“çš„æªæ–½ï¼Œä»¥ä¾¿ LLM ä¸ä¼šæ›´åŠ é‡è§†åŒ…å«æ›´å¤šç¤ºä¾‹çš„æ ‡ç­¾ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è®¡ç®—ç±»åˆ«æƒé‡ã€‚\n\nç±»åˆ«æƒé‡å‘Šè¯‰æˆ‘ä»¬å¿…é¡»èµ‹äºˆæ¯ä¸ªç±»åˆ«å¤šå¤§çš„é‡è¦æ€§ï¼›ç±»åˆ«æƒé‡è¶Šå¤§ï¼Œè¯¥ç±»åˆ«çš„é‡è¦æ€§å°±è¶Šå¤§ã€‚å¦‚æœæˆ‘ä»¬çš„æ•°æ®é›†ä¸å¹³è¡¡ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºæ ‡ç­¾æä¾›æ›´å¤šçš„ç±»åˆ«æƒé‡ï¼Œä½¿ç”¨æ›´å°‘çš„ç¤ºä¾‹ï¼Œä»è€Œèµ‹äºˆå®ƒæ›´å¤§çš„é‡è¦æ€§ã€‚ä¸ºäº†è·å¾—è¿™äº›ç±»åˆ«æƒé‡ï¼Œæˆ‘ä»¬å¯ä»¥å–æ•°æ®é›†ä¸­ç±»åˆ«æ ‡ç­¾ï¼ˆå€¼è®¡æ•°ï¼‰æ¯”ä¾‹çš„å€’æ•°ã€‚æ­¤ä»£ç å¦‚ä¸‹ï¼š","metadata":{}},{"cell_type":"code","source":"import torch\n\nclass_weights=(1/train_df.label.value_counts(normalize=True).sort_index()).tolist()\nclass_weights=torch.tensor(class_weights)\nclass_weights=class_weights/class_weights.sum()\n\nclass_weights","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:39:17.231665Z","iopub.execute_input":"2024-08-15T04:39:17.232040Z","iopub.status.idle":"2024-08-15T04:39:19.229060Z","shell.execute_reply.started":"2024-08-15T04:39:17.232011Z","shell.execute_reply":"2024-08-15T04:39:19.227893Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([0.2500, 0.2500, 0.2500, 0.2500])"},"metadata":{}}]},{"cell_type":"markdown","source":"ä»è¾“å‡ºä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ‰€æœ‰ç±»åˆ«çš„ç±»åˆ«æƒé‡éƒ½æ˜¯ç›¸ç­‰çš„ï¼›è¿™æ˜¯å› ä¸ºæ‰€æœ‰ç±»åˆ«éƒ½æœ‰ç›¸åŒæ•°é‡çš„ç¤ºä¾‹ã€‚","metadata":{}},{"cell_type":"markdown","source":"æˆ‘ä»¬å°†ä¸‹è½½å¹¶å‡†å¤‡æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚é¦–å…ˆæ˜¯ä¸‹è½½æ¨¡å‹ã€‚æˆ‘ä»¬æ— æ³•ä½¿ç”¨å®Œæ•´æ¨¡å‹ï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨å¤„ç†ä¸€ä¸ªå°å‹ GPUï¼›å› æ­¤ï¼Œæˆ‘ä»¬å°†å¯¹å…¶è¿›è¡Œé‡åŒ–ã€‚æ­¤ä»£ç å¦‚ä¸‹ï¼š","metadata":{}},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig, AutoModelForSequenceClassification\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit = True, \n    bnb_4bit_quant_type = 'nf4',\n    bnb_4bit_use_double_quant = True, \n    bnb_4bit_compute_dtype = torch.bfloat16 \n)\n\nmodel_name = \"NousResearch/Meta-Llama-3-8B\" # \"meta-llama/Meta-Llama-3-8B\"\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    quantization_config=quantization_config,\n    num_labels=4,\n    device_map='auto'\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:41:37.052936Z","iopub.execute_input":"2024-08-15T04:41:37.053726Z","iopub.status.idle":"2024-08-15T04:49:24.323599Z","shell.execute_reply.started":"2024-08-15T04:41:37.053692Z","shell.execute_reply":"2024-08-15T04:49:24.322556Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c0ed71da52c46abaad40c60057cd030"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dd445078e2241249a454fdd4de47308"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e6d9a16ad1440cfbc8fb7a54ae7506a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6277a33cd7fc4b15992735938d9f41b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42df290bc7f8473c894ae969a1ef0813"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d505c647732944c4b602ad568f90d152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"667df59beb134e9dbe89f1d6b364d73f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df3676e1fd2748d4b8d5322e05af6ab8"}},"metadata":{}},{"name":"stderr","text":"Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at NousResearch/Meta-Llama-3-8B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"å› æ­¤ï¼Œè¿è¡Œä¸Šè¿°ä»£ç å°†ä» HuggingFace ä¸­å¿ƒä¸‹è½½ Llama 3 8B å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ ¹æ®æˆ‘ä»¬ä¸ºå…¶æä¾›çš„ quantization_config å¯¹å…¶è¿›è¡Œé‡åŒ–ï¼Œç„¶åå°† LLM çš„è¾“å‡ºå¤´æ›¿æ¢ä¸ºå…·æœ‰ 4 ä¸ªç¥ç»å…ƒçš„çº¿æ€§å¤´ä½œä¸ºè¾“å‡ºï¼Œå¹¶å°†æ¨¡å‹æ¨é€åˆ° GPUã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä¸ºæ¨¡å‹åˆ›å»ºä¸€ä¸ª LoRA é…ç½®ï¼Œä»¥ä»…è®­ç»ƒä¸€éƒ¨åˆ†å‚æ•°ã€‚æ­¤ä»£ç å¦‚ä¸‹ï¼š","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n\nlora_config = LoraConfig(\n    r = 16, \n    lora_alpha = 8,\n    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n    lora_dropout = 0.05, \n    bias = 'none',\n    task_type = 'SEQ_CLS'\n)\n\n# é€‰æ‹©åˆé€‚çš„target_modulesï¼šhttps://github.com/huggingface/peft/blob/main/src/peft/utils/constants.py#L78\n\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:55:14.425343Z","iopub.execute_input":"2024-08-15T04:55:14.426410Z","iopub.status.idle":"2024-08-15T04:55:14.900412Z","shell.execute_reply.started":"2024-08-15T04:55:14.426362Z","shell.execute_reply":"2024-08-15T04:55:14.899509Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"è¿è¡Œæ­¤ç¨‹åºåï¼Œget_peft_model å°†é‡‡ç”¨æ¨¡å‹å¹¶é€šè¿‡åŒ…è£…æ¨¡å‹å’Œ LoRA é…ç½®æ¥å‡†å¤‡ä½¿ç”¨PEFT æ–¹æ³•ï¼ˆå¦‚æœ¬ä¾‹ä¸­çš„LoRAï¼‰è¿›è¡Œè®­ç»ƒã€‚","metadata":{}},{"cell_type":"markdown","source":"æˆ‘ä»¬å°†åœ¨æ¨¡å‹è®­ç»ƒä¹‹å‰åœ¨æµ‹è¯•æ•°æ®ä¸Šæµ‹è¯• Llama 3 æ¨¡å‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†é¦–å…ˆä¸‹è½½æ ‡è®°å™¨ã€‚æ­¤ä»£ç å¦‚ä¸‹ï¼š","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_name = \"NousResearch/Meta-Llama-3-8B\" # \"meta-llama/Meta-Llama-3-8B\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n\ntokenizer.pad_token_id = tokenizer.eos_token_id\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:55:56.284803Z","iopub.execute_input":"2024-08-15T04:55:56.285533Z","iopub.status.idle":"2024-08-15T04:55:58.189671Z","shell.execute_reply.started":"2024-08-15T04:55:56.285499Z","shell.execute_reply":"2024-08-15T04:55:58.188596Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"494b758f15954ca18a33c87e2d617996"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9c12e4effed4998bd31e2e6b3191c42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"942b576376c44b87bf4b63ad364a1c99"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:56:47.014748Z","iopub.execute_input":"2024-08-15T04:56:47.015545Z","iopub.status.idle":"2024-08-15T04:56:47.020508Z","shell.execute_reply.started":"2024-08-15T04:56:47.015508Z","shell.execute_reply":"2024-08-15T04:56:47.019510Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç”šè‡³é€šè¿‡å°†æ¨¡å‹çš„ pad token ID è®¾ç½®ä¸º tokenizer çš„ pad token ID æ¥ç¼–è¾‘æ¨¡å‹é…ç½®ï¼Œå¹¶ä¸”ä¸ä½¿ç”¨ç¼“å­˜ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†æµ‹è¯•æ•°æ®æä¾›ç»™æ¨¡å‹å¹¶æ”¶é›†è¾“å‡ºï¼š","metadata":{}},{"cell_type":"code","source":"sentences = test_df.text.tolist()\nbatch_size = 16  \nall_outputs = []\n\nfor i in range(0, len(sentences), batch_size):\n    batch_sentences = sentences[i:i + batch_size]\n\n    inputs = tokenizer(batch_sentences, return_tensors=\"pt\", \n    padding=True, truncation=True, max_length=512)\n\n    inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n        all_outputs.append(outputs['logits'])\n        \nfinal_outputs = torch.cat(all_outputs, dim=0)\ntest_df['predictions']=final_outputs.argmax(axis=1).cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:57:05.911352Z","iopub.execute_input":"2024-08-15T04:57:05.911715Z","iopub.status.idle":"2024-08-15T05:03:22.346163Z","shell.execute_reply.started":"2024-08-15T04:57:05.911686Z","shell.execute_reply":"2024-08-15T05:03:22.345224Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"2024-08-15 04:57:11.476773: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-15 04:57:11.476896: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-15 04:57:11.603893: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"è¿è¡Œæ­¤ä»£ç ä¼šå°†æ¨¡å‹ç»“æœå­˜å‚¨åœ¨ä¸€ä¸ªå˜é‡ä¸­ã€‚æˆ‘ä»¬å°†è¿™äº›é¢„æµ‹æ·»åŠ åˆ°æ–°åˆ—ä¸­çš„æµ‹è¯• DataFrame ä¸­ã€‚æˆ‘ä»¬å–æ¯ä¸ªè¾“å‡ºçš„ argmaxï¼›è¿™ä¸ºæˆ‘ä»¬æä¾›äº† final_outputs åˆ—è¡¨ä¸­æ¯ä¸ªè¾“å‡ºæ¦‚ç‡æœ€é«˜çš„æ ‡ç­¾ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦è¯„ä¼° LLM ç”Ÿæˆçš„è¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç è¿›è¡Œè¯„ä¼°ï¼š","metadata":{}},{"cell_type":"markdown","source":"è¿è¡Œè¯¥ç¨‹åºäº§ç”Ÿäº†ä»¥ä¸‹ç»“æœã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬çš„å‡†ç¡®ç‡ä¸º 0.21ï¼Œè¿™éå¸¸ä½ã€‚è¯¥æ¨¡å‹çš„å‡†ç¡®ç‡ã€å¬å›ç‡å’Œ f1 åˆ†æ•°ä¹Ÿéå¸¸ä½ï¼›å®ƒä»¬ç”šè‡³æ²¡æœ‰è¾¾åˆ° 50% ä»¥ä¸Šçš„ç™¾åˆ†æ¯”ã€‚åœ¨è®­ç»ƒæ¨¡å‹åå¯¹å®ƒä»¬è¿›è¡Œæµ‹è¯•å°†è®©æˆ‘ä»¬äº†è§£æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import balanced_accuracy_score, classification_report\n\ndef get_metrics_result(test_df):\n    y_test = test_df.label\n    y_pred = test_df.predictions\n\n    print(\"Classification Report:\")\n    print(classification_report(y_test, y_pred))\n\n    print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n\nget_metrics_result(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:03:56.641658Z","iopub.execute_input":"2024-08-15T05:03:56.642403Z","iopub.status.idle":"2024-08-15T05:03:57.349544Z","shell.execute_reply.started":"2024-08-15T05:03:56.642368Z","shell.execute_reply":"2024-08-15T05:03:57.348487Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.37      0.24      0.29       500\n           1       0.38      0.07      0.12       500\n           2       0.18      0.31      0.22       500\n           3       0.18      0.26      0.21       500\n\n    accuracy                           0.22      2000\n   macro avg       0.28      0.22      0.21      2000\nweighted avg       0.28      0.22      0.21      2000\n\nBalanced Accuracy Score: 0.2185\nAccuracy Score: 0.2185\n","output_type":"stream"}]},{"cell_type":"markdown","source":"åœ¨å¼€å§‹è®­ç»ƒä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œç„¶åå†å°†å…¶å‘é€åˆ°æ¨¡å‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š","metadata":{}},{"cell_type":"code","source":"def data_preprocesing(row):\n    return tokenizer(row['text'], truncation=True, max_length=512)\n\ntokenized_data = dataset.map(data_preprocesing, batched=True, \nremove_columns=['text'])\ntokenized_data.set_format(\"torch\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:04:51.762590Z","iopub.execute_input":"2024-08-15T05:04:51.763267Z","iopub.status.idle":"2024-08-15T05:04:53.778695Z","shell.execute_reply.started":"2024-08-15T05:04:51.763238Z","shell.execute_reply":"2024-08-15T05:04:53.777692Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ce9904e3f0c472a88677c17684b53cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce967de7135149cd8f0898737121d248"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fcb4b9cbbca4cf6a7c9d0507d704c3b"}},"metadata":{}}]},{"cell_type":"markdown","source":"ç°åœ¨ï¼Œdatasetdict ä¸­çš„æ¯ä¸ªæ•°æ®é›†éƒ½åŒ…å«ä¸‰ä¸ªç‰¹å¾/åˆ—ï¼Œå³æ ‡ç­¾ã€input_id å’Œ Attention_masksã€‚ä½¿ç”¨ä¸Šè¿°é¢„å¤„ç†å‡½æ•°ä¸ºæ¯ä¸ªæ–‡æœ¬ç”Ÿæˆ input_ids å’Œ Attention_masksã€‚åœ¨è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ•°æ®æ•´ç†å™¨æ¥æ‰¹é‡å¤„ç†æ•°æ®ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ncollate_fn = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:05:03.784210Z","iopub.execute_input":"2024-08-15T05:05:03.784597Z","iopub.status.idle":"2024-08-15T05:05:03.809108Z","shell.execute_reply.started":"2024-08-15T05:05:03.784568Z","shell.execute_reply":"2024-08-15T05:05:03.808319Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"è¿™å°†ç¡®ä¿æ‰¹å¤„ç†ä¸­çš„æ‰€æœ‰è¾“å…¥å…·æœ‰ç›¸åŒçš„é•¿åº¦ï¼Œè¿™å¯¹äºåŠ å¿«è®­ç»ƒé€Ÿåº¦è‡³å…³é‡è¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ç‰¹æ®Šæ ‡è®°ï¼ˆå¦‚å¡«å……æ ‡è®°ï¼‰å°†è¾“å…¥ç»Ÿä¸€å¡«å……åˆ°æœ€é•¿åºåˆ—é•¿åº¦ï¼Œä»è€Œå…è®¸åŒæ—¶è¿›è¡Œæ‰¹å¤„ç†ã€‚","metadata":{}},{"cell_type":"markdown","source":"åœ¨å¼€å§‹è®­ç»ƒä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªè¯¯å·®åº¦é‡æ¥è¯„ä¼°å®ƒã€‚å¤§å‹è¯­è¨€æ¨¡å‹çš„é»˜è®¤è¯¯å·®åº¦é‡æ˜¯è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±ã€‚ä½†åœ¨è¿™é‡Œï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨ä¿®æ”¹ LLM ä»¥ä½¿å…¶æˆä¸ºåºåˆ—åˆ†ç±»å·¥å…·ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦é‡æ–°å®šä¹‰åœ¨è®­ç»ƒæ—¶æµ‹è¯•æ¨¡å‹æ‰€éœ€çš„è¯¯å·®åº¦é‡ï¼š","metadata":{}},{"cell_type":"code","source":"def compute_metrics(evaluations):\n    predictions, labels = evaluations\n    predictions = np.argmax(predictions, axis=1)\n    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),\n    'accuracy':accuracy_score(predictions,labels)}","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:05:17.336515Z","iopub.execute_input":"2024-08-15T05:05:17.337134Z","iopub.status.idle":"2024-08-15T05:05:17.342267Z","shell.execute_reply.started":"2024-08-15T05:05:17.337095Z","shell.execute_reply":"2024-08-15T05:05:17.341358Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"å› ä¸ºæˆ‘ä»¬è¦ä½¿ç”¨è‡ªå®šä¹‰æŒ‡æ ‡ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”šè‡³å®šä¹‰äº†ä¸€ä¸ªè‡ªå®šä¹‰è®­ç»ƒå™¨æ¥è®­ç»ƒæˆ‘ä»¬çš„ LLMï¼Œè¿™æ˜¯å¿…è¦çš„ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨ç±»æƒé‡ã€‚ä¸ºæ­¤ï¼Œä»£ç å°†æ˜¯","metadata":{}},{"cell_type":"code","source":"from transformers import Trainer\n\nclass CustomTrainer(Trainer):\n    def __init__(self, *args, class_weights=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        if class_weights is not None:\n            self.class_weights = torch.tensor(class_weights, \n            dtype=torch.float32).to(self.args.device)\n        else:\n            self.class_weights = None\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\").long()\n\n        outputs = model(**inputs)\n\n        logits = outputs.get('logits')\n\n        if self.class_weights is not None:\n            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n        else:\n            loss = F.cross_entropy(logits, labels)\n\n        return (loss, outputs) if return_outputs else loss","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:06:13.633247Z","iopub.execute_input":"2024-08-15T05:06:13.634207Z","iopub.status.idle":"2024-08-15T05:06:14.178482Z","shell.execute_reply.started":"2024-08-15T05:06:13.634152Z","shell.execute_reply":"2024-08-15T05:06:14.177209Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"ç°åœ¨ï¼Œæˆ‘ä»¬å°†å®šä¹‰æˆ‘ä»¬çš„è®­ç»ƒå‚æ•°ã€‚ä»£ç å¦‚ä¸‹ï¼š","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir = 'sentiment_classification',\n    learning_rate = 1e-4,\n    per_device_train_batch_size = 8,\n    per_device_eval_batch_size = 8,\n    num_train_epochs = 1,\n    logging_steps=1,\n    weight_decay = 0.01,\n    evaluation_strategy = 'epoch',\n    save_strategy = 'epoch',\n    load_best_model_at_end = True,\n    report_to=\"none\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:08:09.058337Z","iopub.execute_input":"2024-08-15T05:08:09.059202Z","iopub.status.idle":"2024-08-15T05:08:09.094738Z","shell.execute_reply.started":"2024-08-15T05:08:09.059172Z","shell.execute_reply":"2024-08-15T05:08:09.093791Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"è¿™å°†åˆ›å»ºæˆ‘ä»¬çš„ TrainingArguments å¯¹è±¡ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å‡†å¤‡å°†å…¶ä¼ é€’ç»™æˆ‘ä»¬åˆ›å»ºçš„ Trainerã€‚æ­¤ä»£ç å¦‚ä¸‹ï¼š","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\nimport numpy as np\n\ntrainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = tokenized_data['train'],\n    eval_dataset = tokenized_data['val'],\n    tokenizer = tokenizer,\n    data_collator = collate_fn,\n    compute_metrics = compute_metrics,\n    class_weights=class_weights,\n)\n\ntrain_result = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:10:37.016600Z","iopub.execute_input":"2024-08-15T05:10:37.016998Z","iopub.status.idle":"2024-08-15T06:36:58.085674Z","shell.execute_reply.started":"2024-08-15T05:10:37.016970Z","shell.execute_reply":"2024-08-15T06:36:58.084078Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/4108302796.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  self.class_weights = torch.tensor(class_weights,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1001' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 1:19:57, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 06:15]\n    </div>\n    "},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CustomTrainer(\n\u001b[1;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m      5\u001b[0m     args \u001b[38;5;241m=\u001b[39m training_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     class_weights\u001b[38;5;241m=\u001b[39mclass_weights,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m train_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2365\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2369\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2793\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2791\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2793\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2796\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2750\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2750\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2753\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3641\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3638\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3640\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3641\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3642\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3644\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3645\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3651\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3923\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3919\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3920\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   3921\u001b[0m         )\n\u001b[1;32m   3922\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3923\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3924\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3925\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n","Cell \u001b[0;32mIn[20], line 3\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(evaluations)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics\u001b[39m(evaluations):\n\u001b[1;32m      2\u001b[0m     predictions, labels \u001b[38;5;241m=\u001b[39m evaluations\n\u001b[0;32m----> 3\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m : balanced_accuracy_score(predictions, labels),\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m:accuracy_score(predictions,labels)}\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"],"ename":"NameError","evalue":"name 'np' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°è¯•è¿›è¡Œè¯„ä¼°ï¼Œåœ¨æµ‹è¯•æ•°æ®ä¸Šæµ‹è¯•æ–°è®­ç»ƒçš„æ¨¡å‹ï¼š","metadata":{}},{"cell_type":"code","source":"def generate_predictions(model,df_test):\n    sentences = df_test.text.tolist()\n    batch_size = 32  \n    all_outputs = []\n\n    for i in range(0, len(sentences), batch_size):\n\n        batch_sentences = sentences[i:i + batch_size]\n\n        inputs = tokenizer(batch_sentences, return_tensors=\"pt\", \n        padding=True, truncation=True, max_length=512)\n\n        inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') \n        for k, v in inputs.items()}\n\n        with torch.no_grad():\n            outputs = model(**inputs)\n            all_outputs.append(outputs['logits'])\n        \n    final_outputs = torch.cat(all_outputs, dim=0)\n    df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n\ngenerate_predictions(model,test_df)\n#get_performance_metrics(test_df)\nget_metrics_result(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:46:01.496237Z","iopub.execute_input":"2024-08-15T06:46:01.497251Z","iopub.status.idle":"2024-08-15T06:52:23.734085Z","shell.execute_reply.started":"2024-08-15T06:46:01.497215Z","shell.execute_reply":"2024-08-15T06:52:23.733091Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.97      0.92      0.94       500\n           1       0.98      1.00      0.99       500\n           2       0.92      0.89      0.90       500\n           3       0.88      0.94      0.91       500\n\n    accuracy                           0.94      2000\n   macro avg       0.94      0.94      0.94      2000\nweighted avg       0.94      0.94      0.94      2000\n\nBalanced Accuracy Score: 0.935\nAccuracy Score: 0.935\n","output_type":"stream"}]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:52:43.882469Z","iopub.execute_input":"2024-08-15T06:52:43.883295Z","iopub.status.idle":"2024-08-15T06:52:44.933615Z","shell.execute_reply.started":"2024-08-15T06:52:43.883262Z","shell.execute_reply":"2024-08-15T06:52:44.932575Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[0m\u001b[01;34msentiment_classification\u001b[0m/\n","output_type":"stream"}]},{"cell_type":"code","source":"cd sentiment_classification/","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:52:55.796586Z","iopub.execute_input":"2024-08-15T06:52:55.797346Z","iopub.status.idle":"2024-08-15T06:52:55.803478Z","shell.execute_reply.started":"2024-08-15T06:52:55.797289Z","shell.execute_reply":"2024-08-15T06:52:55.802525Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"/kaggle/working/sentiment_classification\n","output_type":"stream"}]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:52:58.113077Z","iopub.execute_input":"2024-08-15T06:52:58.113483Z","iopub.status.idle":"2024-08-15T06:52:59.149697Z","shell.execute_reply.started":"2024-08-15T06:52:58.113450Z","shell.execute_reply":"2024-08-15T06:52:59.148568Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[0m\u001b[01;34mcheckpoint-1000\u001b[0m/\n","output_type":"stream"}]},{"cell_type":"code","source":"cd checkpoint-1000","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:53:13.444138Z","iopub.execute_input":"2024-08-15T06:53:13.444888Z","iopub.status.idle":"2024-08-15T06:53:13.452619Z","shell.execute_reply.started":"2024-08-15T06:53:13.444852Z","shell.execute_reply":"2024-08-15T06:53:13.451674Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"/kaggle/working/sentiment_classification/checkpoint-1000\n","output_type":"stream"}]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:53:15.596471Z","iopub.execute_input":"2024-08-15T06:53:15.597250Z","iopub.status.idle":"2024-08-15T06:53:16.632326Z","shell.execute_reply.started":"2024-08-15T06:53:15.597217Z","shell.execute_reply":"2024-08-15T06:53:16.631197Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"README.md                  rng_state.pth            tokenizer_config.json\nadapter_config.json        scheduler.pt             trainer_state.json\nadapter_model.safetensors  special_tokens_map.json  training_args.bin\noptimizer.pt               tokenizer.json\n","output_type":"stream"}]},{"cell_type":"code","source":"ll","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:53:38.131635Z","iopub.execute_input":"2024-08-15T06:53:38.132580Z","iopub.status.idle":"2024-08-15T06:53:39.161063Z","shell.execute_reply.started":"2024-08-15T06:53:38.132536Z","shell.execute_reply":"2024-08-15T06:53:39.160025Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"total 169308\n-rw-r--r-- 1 root      5102 Aug 15 06:30 README.md\n-rw-r--r-- 1 root       710 Aug 15 06:30 adapter_config.json\n-rw-r--r-- 1 root  54626008 Aug 15 06:30 adapter_model.safetensors\n-rw-r--r-- 1 root 109399354 Aug 15 06:30 optimizer.pt\n-rw-r--r-- 1 root     14244 Aug 15 06:30 rng_state.pth\n-rw-r--r-- 1 root      1064 Aug 15 06:30 scheduler.pt\n-rw-r--r-- 1 root       335 Aug 15 06:30 special_tokens_map.json\n-rw-r--r-- 1 root   9085796 Aug 15 06:30 tokenizer.json\n-rw-r--r-- 1 root     50628 Aug 15 06:30 tokenizer_config.json\n-rw-r--r-- 1 root    151864 Aug 15 06:30 trainer_state.json\n-rw-r--r-- 1 root      5112 Aug 15 06:30 training_args.bin\n","output_type":"stream"}]},{"cell_type":"markdown","source":"æœ¬æ–‡å‚è€ƒï¼šhttps://www.analyticsvidhya.com/blog/2024/06/finetuning-llama-3-for-sequence-classification/","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}